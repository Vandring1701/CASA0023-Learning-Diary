[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "CASA0023 Learning Diary",
    "section": "",
    "text": "Welcome\nThis site contains my learning diary entries for the course CASA0023 Remotely Sensing Cities and Environments at UCL.\nEach week includes reflections, applications, and references, together with any outputs from practicals or readings.\n\nAcknowledgements:\nThis site is built using Quarto.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Welcome</span>"
    ]
  },
  {
    "objectID": "week1.html",
    "href": "week1.html",
    "title": "Getting started with remote sensing",
    "section": "",
    "text": "Summary\nThe first week of this course was interesting, setting the foundation on remote sensing. I was surprised about how immense the scope is—being practically anything including just satellite imagery. It involves data coming from satellites, drones, aerial photography, and furthermore from possibly even handheld devices, collected by either passive or active sensors. Passive sensors detect energy reflected from the sun located in the electromagnetic spectrum, whereas active systems like SAR emit their signal, meaning they can capture data through clouds or at night. This becomes a big selling point for an area like the UK where optical data capture might get severely compromised due to cloud cover.\nOther lecture topics were about electromagnetic wave interaction with Earth surface and atmosphere, including scattering, absorption, and reflection. I enjoyed the everyday science examples, like why the sky is blue or why the ocean appears blue, because they made abstract physical concepts more accessible. Another highlight was the introduction of the four major types of resolution in remote sensing: spatial, spectral, temporal, and radiometric. Each of these resolutions is important in programmed use of data, and in view of this, their word combinations present the challenges of actual analysis.\nAlthough we have yet to do any labs, the lecture mentioned SNAP and R. I am sure these are the environments that will be used to load and process Landsat and Sentinel data. Next week, I strongly look forward to getting my hands dirty and seeing theory put into practice.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Getting started with remote sensing</span>"
    ]
  },
  {
    "objectID": "week1.html#applications",
    "href": "week1.html#applications",
    "title": "Getting started with remote sensing",
    "section": "Applications",
    "text": "Applications\nThe lecture provided me with some insight into why there are different strengths and weaknesses with different sensors and how mixing datasets is a powerful solution. Gao et al. (2006) are a good example to learn from as the authors lead the way in investigating the fusion of MODIS and Landsat data. MODIS provides images frequently but does not provide a good resolution of the data. More detailed photographs are taken by Landsat, however, these have a lower rate of acquisition only once every 16 days.\nResponding to such a dilemma, Gao et al. (2006) recommend a fusion based mechanism for tracking and predicting Landsat reflectance at daily intervals, using Landsat data and MODIS data. In this case, they found a way out of real-world constraints with ingenious tactical data analysis. It means that there exists an approach depending on such factors to overcome the design limitations which are seemingly insurmountable.\nAnother proved point is the work by Hemati et al. (2021) which provides a comprehensive survey of the use of Landsat in environmental monitoring for 5 decades. The authors also point out that Landsat is useful in studying aspects of urbanization, deforestation, agriculture, and natural catastrophes. Another emphasized change was in the radiometric resolution that was made much better to allow for the detection of smaller changes. More about changes in Landsat would not apply because the technology is too advanced to very small changes of surface reflectance which the contrast with the older technology is quite immodest.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Getting started with remote sensing</span>"
    ]
  },
  {
    "objectID": "week1.html#reflection",
    "href": "week1.html#reflection",
    "title": "Getting started with remote sensing",
    "section": "Reflection",
    "text": "Reflection\nUp to this point, my vision towards remote sensing was closely connected with its beautiful satellite images and climate reports. Currently, it is perceived as a professional technique which involves an analysis of intricate interrelation of parameters with respect to difficult decisions with respect to sensor options, data types, location and presence of contaminants in the atmosphere.\nThe facet that captivated me in particular was the spectral signatures: in other words, every object on the globe absorbs and reproduces the radiant energy differently based on its nature. This serves as a great potential on environmental research from forest cutting watch to plant diseased detection to infrastructure mapping. For me, the most practical lesson was the remote sensing getting off high horses and discovering how it works instead of just reading the narcissistic loftiness of other intellectuals.\nThey also referred to remote sensing data, not geographic clockwise paper and shaped blue areas (fundamental units for object-based classification, geometry). They contended that perhaps as a result of that very complexity, it was evident that remote sensing had not been widely incorporated into municipal datasets by developers—suggesting that perhaps as a result of that very complexity. But with things like Google Earth Engine at our disposal, and the availability of Landsat and Sentinel data, one could definitely foresee the potential in remote sensing as a means of enhancing the view of spatial data and such analytical techniques, especially in areas remote from in-situ data.\nPersonally, I support the idea of using remote sensing in urban climate planning and management efforts.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Getting started with remote sensing</span>"
    ]
  },
  {
    "objectID": "week1.html#references",
    "href": "week1.html#references",
    "title": "Getting started with remote sensing",
    "section": "References",
    "text": "References\n\nGao, F., Masek, J., Schwaller, M. and Hall, F., 2006. On the blending of the Landsat and MODIS surface reflectance: Predicting daily Landsat surface reflectance. IEEE Transactions on Geoscience and Remote Sensing, 44(8), pp.2207-2218.\n\nHemati, M., Hasanlou, M., Mahdianpari, M. and Mohammadimanesh, F., 2021. A systematic review of Landsat data for change detection applications: 50 years of monitoring the Earth. Remote Sensing, 13(15), p.2869.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Getting started with remote sensing</span>"
    ]
  },
  {
    "objectID": "week5.html",
    "href": "week5.html",
    "title": "Google Earth Engine I",
    "section": "",
    "text": "Summary\nGeography—this week introduced Google Earth Engine (GEE), the cloud platform for planetary-scale geospatial analysis. In its capabilities it combines a multi-petabyte archive of satellite imagery, enabling an investigator to analyse and visualise changes on the Earth’s surface directly from a browser through the APIs of JavaScript or Python. One of the best things of this platform is that it is very accessible; rather than forcing a user to download terabytes of satellite data locally, the user accesses one of the many pre-hosted image collections such as Landsat, Sentinel, MODIS, and many others, and can execute their highly complicated algorithm right there in the cloud.\nWe also learned about zonal statistics types such as using reduceRegion() for summarising pixel values over a feature, or reduceRegions(), which applies the same operation over a feature collection. Time-series processing is covered in the lecture, including linear trend analyses per-pixel using linearFit() and linearRegression() functions. With these functions, users can detect long-term patterns such as vegetation change or urban growth; I was not aware that it was so straightforward to do this within a browser-based tool.\nThe practical section gave examples of computing NDVI in GEE, filtering satellite images by date and cloud cover, clipping them to the region of interest, and then applying reducers to summarise data over time and space. We did not undertake a full analysis just yet, but these code examples were relevant and helpful, and I now feel capable of writing my own scripts in GEE.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Google Earth Engine I</span>"
    ]
  },
  {
    "objectID": "week5.html#applications",
    "href": "week5.html#applications",
    "title": "Google Earth Engine I",
    "section": "Applications",
    "text": "Applications\nThe introduced tools are potentially suited for a wide range of environmental monitoring and change-detection tasks. In the words of Doblas et al. (2022), DETER-R is presented as a near-real-time alert system for forest disturbances in the Brazilian Amazon. It is based on Sentinel-1 time series data processed in GEE. Making full use of GEE in managing extensive image collections, deforestation could be monitored even in circumstances of incessant cloud cover, and radar imagery was the key to that ability. The system performs weekly time-series analyses to detect anomalies in backscatter values that may have denoted loss in tree cover.\nThere is ample room for the development of the concepts we covered in class, especially the map() function applied to time series, reducers used to aggregate technical indicators, and classifiers for identifying abrupt changes. Hao et al. (2019) provide another case study on the utilization of GEE in the study of the Three Gorges Reservoir over a period of 15 years in terms of land use change and climate change-induced variations. Their technique included selecting data, setting area and dates, creating masks for clouds, and examining seasonal medians. This closely mirrored what we were learning in class, and showed how GEE facilitates efficient analysis of large datasets across various geographies and timeframes.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Google Earth Engine I</span>"
    ]
  },
  {
    "objectID": "week5.html#reflection",
    "href": "week5.html#reflection",
    "title": "Google Earth Engine I",
    "section": "Reflection",
    "text": "Reflection\nThis week was very important because I learned more about current geo-spatial data processing procedures that are increasingly cloud-based, including direct sensor integration. The introduction of Google Earth Engine totally changed how I saw remote sensing. In the past, working with satellite images required heavy equipment, powerful computers, and lengthy downloads. Now, many of these barriers have been removed.\nThe use of Google Earth Engine encourages the principles of open science; scripts can be easily shared via links, projects are reproducible, and research is more transparent. This also allows results to be shared with non-professionals, policymakers, or community groups with limited resources. As a consequence, the ability to work with global EO data archives is extremely helpful for those without access to powerful computer infrastructure.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Google Earth Engine I</span>"
    ]
  },
  {
    "objectID": "week5.html#references",
    "href": "week5.html#references",
    "title": "Google Earth Engine I",
    "section": "References",
    "text": "References\nDoblas, J., Reis, M.S., Belluzzo, A.P., Quadros, C.B., Moraes, D.R., Almeida, C.A., Maurano, L.E., Carvalho, A.F., Sant’Anna, S.J. and Shimabukuro, Y.E., 2022. DETER-R: an operational near-real time tropical forest disturbance warning system based on Sentinel-1 time series analysis. Remote Sensing, 14(15), p.3658.\nHao, B., Ma, M., Li, S., Li, Q., Hao, D., Huang, J., Ge, Z., Yang, H. and Han, X., 2019. Land use change and climate variation in the Three Gorges Reservoir catchment from 2000 to 2015 based on the Google Earth Engine. Sensors, 19(9), p.2118.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Google Earth Engine I</span>"
    ]
  },
  {
    "objectID": "week6.html",
    "href": "week6.html",
    "title": "Classification",
    "section": "",
    "text": "Summary\nImage classification in remote sensing is the major application explored in this week’s group. Image classification refers to the process of assigning every pixel an accurate land cover class (e.g., water bodies, vegetation, urban structures) through algorithms, with the result being a land cover map that can easily be interpreted by humans.\nTwo broad classes of classification methods were covered: Supervised Classification and Unsupervised Classification.\n- Supervised classification uses training samples (feature information labeled by the user) to train classification models.\n- Unsupervised classification clusters pixels automatically based on spectral similarity.\nThe reliability of training samples was emphasized: poor training sites reduce classification accuracy and undermine validation (as highlighted in Samara et al.). Accuracy close to 100% cannot be judged without methods like the Confusion Matrix, Overall Accuracy, and Kappa Coefficient, which assess correctness and model generalization.\nIn practice, we implemented a workflow in Google Earth Engine (GEE):\n1. Draw ROI samples\n2. Group classes for training\n3. Select classifiers (CART or SVM)\n4. Run classification\n5. Visualize and evaluate results\nThis week’s topics showed strong applicability to real research contexts.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Classification</span>"
    ]
  },
  {
    "objectID": "week6.html#application",
    "href": "week6.html#application",
    "title": "Classification",
    "section": "Application",
    "text": "Application\nZak and Cabido (2002) conducted a vegetation study in the Chaco region of Argentina, combining ground-based community registries, photogrammetric aerial images, and spectral reflectance. Vegetation type strongly influenced band reflectance, forming the basis for classification.\nAnother study by Deval and Joshi (2022) assessed vegetation and land cover mapping in semi-arid wetlands of India using MLC, SVM, and RF classifiers. Results showed SVM performed best when spectral overlaps between classes were high, confirming its strength in handling inseparable and nonlinear datasets.\nThese examples illustrate how image classification can bridge zonal vs. fine-scale assessments, and how classifier choice affects outputs in ecological and climate-related research.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Classification</span>"
    ]
  },
  {
    "objectID": "week6.html#reflection",
    "href": "week6.html#reflection",
    "title": "Classification",
    "section": "Reflection",
    "text": "Reflection\nI learned that classification of remote sensing imagery requires much more than automated sorting. It demands:\n- Careful training sample selection\n- Parameter tuning\n- Justification of classifier choice\n- Thoughtful evaluation approaches\nThe GEE code provided in class helped visualize how different classifiers split data, reinforcing that trial, comparison, and iteration are essential to robust analysis.\nI also realized how classifier characteristics affect applications:\n- CART is hard to calibrate but useful in structured datasets.\n- SVM handles high-dimensional, small-sample, nonlinear datasets better.\nThis learning will support my own project on urban heat islands, where classification of land cover (green spaces vs. soil surfaces) will be a fundamental step.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Classification</span>"
    ]
  },
  {
    "objectID": "week6.html#references",
    "href": "week6.html#references",
    "title": "Classification",
    "section": "References",
    "text": "References\nZak, M.R. and Cabido, M., 2002. Spatial patterns of the Chaco vegetation of central Argentina: Integration of remote sensing and phytosociology. Applied Vegetation Science, 5(2), pp.213–226.\nDeval, K. and Joshi, P.K., 2022. Vegetation type and land cover mapping in a semi-arid heterogeneous forested wetland of India: Comparing image classification algorithms. Environment, Development and Sustainability, 24(3), pp.3947–3966.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Classification</span>"
    ]
  },
  {
    "objectID": "week7.html",
    "href": "week7.html",
    "title": "Classification II",
    "section": "",
    "text": "Summary\nThis week focused on Accuracy Assessment and Cross-Validation. Accuracy assessment is essential for evaluating classification results in terms of reliability, while cross-validation ensures that models generalise effectively.\nWe learned about measures such as the Confusion Matrix, Overall Accuracy (OA), Producer’s Accuracy, and User’s Accuracy. In particular, the module emphasised Leave-One-Out Cross-Validation (LOOCV), useful when data is scarce or imbalanced. LOOCV involves leaving out one observation for testing while using the rest for training, repeating this for all data points, and then averaging the errors. Although computationally demanding, LOOCV yields reliable numerical results — making it especially relevant in remote sensing tasks where high accuracy is crucial.\nPractically, we learned how to sample data in Google Earth Engine (GEE), splitting a region of interest into training and testing sets with randomColumn() and fillerMetadata(). GEE also provides tools to generate confusion matrices, classification reports, and performance metrics, enhancing spatial data evaluation.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Classification II</span>"
    ]
  },
  {
    "objectID": "week7.html#application",
    "href": "week7.html#application",
    "title": "Classification II",
    "section": "Application",
    "text": "Application\nBrownlee (2020) explains that LOOCV is a special case of k-fold cross-validation where only one sample is used for testing at each step. This method maximises training data usage and improves stability and generalisation, though it is computationally expensive. It is especially helpful when overfitting is likely or when data is scarce.\nKarasiak et al. (2021) discuss limitations of LOOCV, noting that while it has low variance, it can introduce bias in certain conditions. They propose combining it with methods like repeated random allocation or bootstrap for more robust results. Their numerical study compared different cross-validation methods for ranking model parameters, showing that there is no “one-size-fits-all” — methodology choice should depend on data characteristics, task difficulty, and deployment goals.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Classification II</span>"
    ]
  },
  {
    "objectID": "week7.html#reflection",
    "href": "week7.html#reflection",
    "title": "Classification II",
    "section": "Reflection",
    "text": "Reflection\nThis week significantly changed my perspective on classification validation. Previously, I often split training and testing data arbitrarily, without standards. Now I appreciate the value of systematic approaches like LOOCV.\nLOOCV initially looks like a simple repetition of training and testing, but it carries scientific rigour: even with small or rare datasets, it provides meaningful evaluation. I also realised that effective cross-validation is not just about running it, but about making deliberate choices regarding fold number, hyperparameter tuning, and algorithm selection.\nThis insight will guide me to design more reliable experiments and avoid misunderstandings in interpreting classification results. Moving forward, I will prioritise structured validation, ensuring my models are robust, reproducible, and credible.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Classification II</span>"
    ]
  },
  {
    "objectID": "week7.html#references",
    "href": "week7.html#references",
    "title": "Classification II",
    "section": "References",
    "text": "References\nBrownlee, J., 2020. LOOCV for Evaluating Machine Learning Algorithms. Machine Learning Mastery, August 26. Available at: https://machinelearningmastery.com/loocv-for-evaluating-machine-learning-algorithms/\nKarasiak, N., Dejoux, J., Monteil, C., & Sheeren, D., 2021. Spatial dependence between training and test sets: another pitfall of classification accuracy assessment in remote sensing. Machine Learning, 111(7), pp.2715–2740. https://doi.org/10.1007/s10994-021-05972-1",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Classification II</span>"
    ]
  }
]